Learning Journal 8

This week's lecture covered the topic of using corpora and corpus data for language assessment and language testing while introducing the assessment of the use of cohesive devices in L2 writing as an example.
Traditionally, guidelines such as the Common European Framework of Reference for Language (CEFR) were used to identify the proficiency levels of L2 learners according to classes ranging from A1 to C2. This kind of assessment is based on so-called descriptors that can either be global, i.e. a general description of the required language skills for every respective level, or specialised, i.e. covering only one dimension of language proficiency. Nowadays, this approach is considered inadequate, because it depends on human rating and is, therefore, very subjective. Also, the descriptors are usually very abstract descriptions so when a certain description actually applies is often quite unclear. In the end, the CEFR is a mere orientation. As a result, the operationalisation of the descriptors using corpora is growing in popularity due to its objectiveness and unbiased assessment. It has, in fact, even become a common approach for major testing companies, since computational tools for automatic assessment facilitate the assessment processes quite significantly.

One of the major methodological approaches used for this form of assessment concerning learner corpus research is the Contrastive Interlanguage Analysis introduced by Granger in 1996. It compares the interlangauge data of learners of different L1 backgrounds with native language data as well as other L1 data in order to research quantitative (overuse and underuse) and qualitative (misuse) differences between them. The basic underlying question is whether the mistakes made by L2 learners are typical of learners with a specific L1 background or if they are generalisable.
When incorporating learner corpora in language assessment processes, there are three main possibilities to do so. The first possibility is a corpus-informed approach. Here, the corpus is used as a reference for the assessment according to the different language proficiency levels. For example, when assessing the skill of public speaking, we compare our collected data with the expectations given by a corpus and evaluate accordingly. For a corpus-based approach, on the other hand, the corpus is used as a source for testing our hypothesis. This is what we're doing in Linguistic Methods. We're testing our hypotheses regarding the use of passive voice by using the corpora at hand. Lastly, the corpus-driven approach refrains from analysing the corpus with a preconceived hypothesis. Instead, the hypothesis stems from the statistical analysis itself.

In language testing in general, it is usually important to examine a variety of variable to get a better and broader picture of the L2 performance and proficiency. This can easily be done using automatic computational assessment programs like CoCoGen, TAALES or COH-METRIX. One of these variables is the eye-movement which can be tracked using eye-trackers. Fewer jumps in the eye-movement is one sign of better cohesion, which is a crucical aspect of language proficiency (cf. CEFR descriptor), in a text since it indicates that the reader has a coherent mental image of the text without having to reread previous paragraphs. I example, however, joint corpus data of the RWTH learner corpus and the expert corpus and a computational tool designed for automatic text cohesion assessment was used. The observation of several dimensions of cohesion is L2 texts in comparison with native writers' texts shows that learners insufficiently use noun overlaps (referential cohesion), strongly overuse causal connectives, while strongly underusing certain temporal connectives like first and until, exhibit insufficient word similarity between paragraphs and have an overall lower lexical density (smaller Type-Token-Rato). The learner texts are, therefore, overall less cohesive.
